import json
import os
from torch.utils.data import Dataset, DataLoader
import torch
from verifier.model_utils import load_model_for_namespace
# class RewardDataset(Dataset)å°†å¯¹è¯æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ‰€éœ€çš„æ ¼å¼
# å°†å¤§é‡çš„å¯¹è¯æ•°æ®æ‰¹é‡è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ ¼å¼
# ç”¨äºè®­ç»ƒverifieræ¨¡å‹ã€‚æš‚æ—¶ä¸éœ€è¦ç”¨ï¼
class RewardDataset(Dataset):

    def __init__(self, data_js, tokenizer, max_length=2048):
        self.data_js = data_js
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.data_js)

    def __getitem__(self, idx):
        prompt_response = self.data_js[idx]['prompt_response']
        label = self.data_js[idx]['label']

        encoded_pair = self.tokenizer.encode_plus(
            prompt_response,
            padding='max_length',
            max_length=self.max_length,
            truncation=True,
            return_tensors='pt'
        )

        return {
            'input_ids': encoded_pair['input_ids'].squeeze(),
            'attention_mask': encoded_pair['attention_mask'].squeeze(),
            'labels': label
        }
# æˆ‘ç°åœ¨éœ€è¦ç”¨çš„æ˜¯è¿™ä¸ªï¼
# class OnlineDataBuilder: ç”¨äºæ„å»ºåœ¨çº¿æ•°æ®
class OnlineDataBuilder:

    def __init__(self, elements, data_template, tokenizer, max_length=2048):
        self.elements = elements
        self.data_template = data_template
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.namespace = None
    
    def set_namespace(self, namespace):
        self.namespace = namespace
    
    def get_element(self):
        return_d = None
        for element_d in self.elements:
            if element_d['namespace'] == self.namespace:
                return_d = element_d
                break
        return return_d
    
    def build_data(self, conversation_tx, response_list):
        element_d = self.get_element()

        if element_d['class_name']:
            input_code = f"class {element_d['class_name']}:\n" + element_d['input_code']
        else:
            input_code = element_d['input_code']
        
        data_samples = []
        for idx, response in enumerate(response_list):
            sample = {
                "prompt_response": self.data_template.format(
                    function_name=element_d['function_name'],
                    input_code=input_code,
                    dependency_path=element_d['dependency_all'].strip(),
                    reference_steps=element_d['reference_steps'].strip(),
                    conversation=conversation_tx,
                    response=response
                ),
                "label": 0
            }
            data_samples.append(sample)
        
        online_dataset = RewardDataset(data_samples, tokenizer=self.tokenizer, max_length=self.max_length)
        online_dataloader = DataLoader(online_dataset, batch_size=1, shuffle=False)
        
        return online_dataloader

    def build_prompt(self, conversation_tx, response_list):
        """
        æ„å»ºpromptå†…å®¹ï¼Œç›´æ¥è¿”å›promptå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸è¿›è¡Œtokenization
        """
        element_d = self.get_element()

        if element_d['class_name']:
            input_code = f"class {element_d['class_name']}:\n" + element_d['input_code']
        else:
            input_code = element_d['input_code']
        
        prompt_list = []
        for idx, response in enumerate(response_list):
            prompt_sample={
                "prompt_response": self.data_template.format(
                function_name=element_d['function_name'],
                input_code=input_code,
                dependency_path=element_d['dependency_all'].strip(),
                reference_steps=element_d['reference_steps'].strip(),
                conversation=conversation_tx,
                response=response
            ),
            "label": 0}
            prompt_list.append(prompt_sample)
        
        return prompt_list


# å‚è€ƒOnlineDataBuilderå†™ä¸€ä¸ªOfflineDataBuilder
class OfflineDataBuilder:

    def __init__(self, elements, data_template, tokenizer, max_length=2048):
        self.elements = elements
        self.data_template = data_template
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.namespace = None
    
    def set_namespace(self, namespace):
        self.namespace = namespace
    
    def get_element(self):
        return_d = None
        for element_d in self.elements:
            if element_d['namespace'] == self.namespace:
                return_d = element_d
                break
        return return_d
    
    def build_data(self, conversation_tx, response_list):
        element_d = self.get_element()

        if element_d['class_name']:
            input_code = f"class {element_d['class_name']}:\n" + element_d['input_code']
        else:
            input_code = element_d['input_code']
        
        data_samples = []
        for idx, response in enumerate(response_list):
            # å¯¹äºofflineæ•°æ®ï¼Œconversation_txåº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¯¹è¯åˆ—è¡¨
            # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°å½“å‰responseå¯¹åº”çš„tutor utteranceåœ¨å¯¹è¯ä¸­çš„ä½ç½®
            # ç„¶ååªå–è¯¥ä½ç½®ä¹‹å‰çš„å¯¹è¯ä½œä¸ºcontext
            conv_ctx = self._get_conversation_context(conversation_tx, idx)
            
            sample = {
                "prompt_response": self.data_template.format(
                    function_name=element_d['function_name'],
                    input_code=input_code,
                    dependency_path=element_d['dependency_all'].strip(),
                    reference_steps=element_d['reference_steps'].strip(),
                    conversation=conv_ctx,
                    response=response
                ),
                "label": 0
            }
            data_samples.append(sample)
        
        online_dataset = RewardDataset(data_samples, tokenizer=self.tokenizer, max_length=self.max_length)
        online_dataloader = DataLoader(online_dataset, batch_size=1, shuffle=False)
        
        return online_dataloader

    def build_prompt(self, conversation_tx, response_list):
        """
        æ„å»ºpromptå†…å®¹ï¼Œç›´æ¥è¿”å›promptå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸è¿›è¡Œtokenization
        """
        element_d = self.get_element()

        if element_d['class_name']:
            input_code = f"class {element_d['class_name']}:\n" + element_d['input_code']
        else:
            input_code = element_d['input_code']
        
        prompt_list = []
        for idx, response in enumerate(response_list):
            # å¯¹äºofflineæ•°æ®ï¼Œconversation_txåº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¯¹è¯åˆ—è¡¨
            # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°å½“å‰responseå¯¹åº”çš„tutor utteranceåœ¨å¯¹è¯ä¸­çš„ä½ç½®
            # ç„¶ååªå–è¯¥ä½ç½®ä¹‹å‰çš„å¯¹è¯ä½œä¸ºcontext
            conv_ctx = self._get_conversation_context(conversation_tx, idx)
            
            prompt_sample={
                "prompt_response": self.data_template.format(
                function_name=element_d['function_name'],
                input_code=input_code,
                dependency_path=element_d['dependency_all'].strip(),
                reference_steps=element_d['reference_steps'].strip(),
                conversation=conv_ctx,
                response=response
            ),
            "label": 0}
            prompt_list.append(prompt_sample)
        
        return prompt_list
    
    def prompt_to_dataloader(self, prompt_list):
        """
        å°†promptåˆ—è¡¨è½¬æ¢ä¸ºDataLoader
        Args:
            prompt_list: åŒ…å«prompt_responseå’Œlabelçš„å­—å…¸åˆ—è¡¨
        Returns:
            DataLoader: ç”¨äºæ¨¡å‹æ¨ç†çš„æ•°æ®åŠ è½½å™¨
        """
        # æ£€æŸ¥tokenizeræ˜¯å¦å­˜åœ¨
        if self.tokenizer is None:
            raise ValueError("Tokenizer is required for prompt_to_dataloader. Please initialize with a tokenizer.")
        # åˆ›å»ºæ•°æ®é›†å’ŒDataLoader
        offline_dataset = RewardDataset(prompt_list, tokenizer=self.tokenizer, max_length=self.max_length)
        offline_dataloader = DataLoader(offline_dataset, batch_size=1, shuffle=False)
        
        return offline_dataloader

    def _get_conversation_context(self, conversation_tx, response_idx):
        """
        è·å–æŒ‡å®šresponse_idxå¯¹åº”çš„å¯¹è¯ä¸Šä¸‹æ–‡
        åªåŒ…å«è¯¥tutor utteranceä¹‹å‰çš„å¯¹è¯
        """
        # å‡è®¾conversation_txæ˜¯ä¸€ä¸ªå¯¹è¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªturn
        # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ç¬¬response_idxä¸ªtutor utteranceåœ¨å¯¹è¯ä¸­çš„ä½ç½®
        tutor_count = 0
        context_end = 0
        
        for i, turn in enumerate(conversation_tx):
            if "tutor" in turn:
                if tutor_count == response_idx:
                    # æ‰¾åˆ°äº†å¯¹åº”çš„tutor utteranceï¼Œcontextåˆ°æ­¤ä¸ºæ­¢
                    context_end = i
                    break
                tutor_count += 1
        
        # è¿”å›è¯¥ä½ç½®ä¹‹å‰çš„å¯¹è¯ä½œä¸ºcontext
        return conversation_tx[:context_end]





def load_json_data(input_file: str):
    data = []
    with open(input_file, 'r') as f:
        for line in f:
            js = json.loads(line)
            data.append(js)
    return data

def load_data(data_file):
    data_dict = {}
    with open(data_file, 'r') as f:
        for line in f:
            js = json.loads(line)
            namespace = js['namespace']
            if namespace not in data_dict:
                data_dict[namespace] = [js]
            else:
                data_dict[namespace].append(js)
    return data_dict

def save_data(data_dict, data_file):
    with open(data_file, 'w') as f:
        for namespace, data in data_dict.items():
            for js in data:
                f.write(json.dumps(js) + '\n')

def compute_process_reward(total_turn, current_turn, outcome_label):
    process_reward = 0
    t = 1
    while t <= current_turn:
        leading_dist = total_turn - t
        weight = (1 - process_reward) * (2*outcome_label - 1) / (leading_dist + 1)
        process_reward = max(process_reward + weight, 0)
        t += 1
    # keep at most 4 decimal places
    process_reward = round(process_reward, 4)
    return process_reward

def build_model_data(elements, dialog, student_level, data_template):
    namespace = dialog['namespace']
    d = None
    for element in elements:
        if element['namespace'] == namespace:
            d = element
            break

    if d['class_name']:
        input_code = f"class {d['class_name']}:\n" + d['input_code']
    else:
        input_code = d['input_code']
    
    if student_level == "low_level":
        student_knowledge = "None"
    elif student_level == "med_level":
        student_knowledge = d["dependency_sampled"].strip()
    else:
        ref_steps = d['reference_steps'].split('2.')[0].strip()
        student_knowledge = "{}\n\n{}".format(d["dependency_sampled"].strip(), ref_steps)
    
    data_samples = []
    conversation = dialog['conversation']
    outcome_label = dialog['outcome_label']
    total_turn = len(conversation) // 2
    idx = 0
    while idx < len(conversation):
        if "tutor" in conversation[idx]:
            current_turn = idx // 2 + 1
            if idx == 0:
                conv_ctx = []
            else:
                conv_ctx = conversation[:idx]
            response = conversation[idx]["tutor"]

            process_reward = compute_process_reward(total_turn, current_turn, outcome_label)
            sample = {
                "namespace": namespace,
                "prompt_response": data_template.format(
                    function_name=d['function_name'],
                    input_code=input_code,
                    dependency_path=d['dependency_all'].strip(),
                    reference_steps=d['reference_steps'].strip(),
                    conversation=conv_ctx,
                    response=response
                ),
                "label": process_reward
            }
        
            idx += 1
            data_samples.append(sample)
        idx += 1
    
    return data_samples


def check_adjust_posttest(posttest_dir):
    # since some examples may not have completions starting from a certain round
    # we need to get completions and eval results from the last round that has completions
    round_dirs = os.listdir(posttest_dir)
    max_round = max([int(round_dir.split('round_')[1]) for round_dir in round_dirs])

    completion_file = os.path.join(posttest_dir, "round_1/completion.jsonl")
    test_file = os.path.join(posttest_dir, "round_1/test_results.jsonl")
    dep_file = os.path.join(posttest_dir, "round_1/dependency_results.jsonl")
    prev_completions = load_data(completion_file)
    prev_tests = load_data(test_file)
    prev_deps = load_data(dep_file)

    for rdx in range(2, max_round + 1):
        completion_file = os.path.join(posttest_dir, f"round_{rdx}/completion.jsonl")
        test_file = os.path.join(posttest_dir, f"round_{rdx}/test_results.jsonl")
        dep_file = os.path.join(posttest_dir, f"round_{rdx}/dependency_results.jsonl")
        cur_completions = load_data(completion_file)
        cur_tests = load_data(test_file)
        cur_deps = load_data(dep_file)
        for namespace, completions in prev_completions.items():
            if namespace not in cur_completions:
                cur_completions[namespace] = completions
                cur_tests[namespace] = prev_tests[namespace]
                cur_deps[namespace] = prev_deps[namespace]
        assert len(cur_completions) == len(prev_completions)
        assert len(cur_tests) == len(prev_tests)
        assert len(cur_deps) == len(prev_deps)
        # save to files
        save_data(cur_completions, completion_file)
        save_data(cur_tests, test_file)
        save_data(cur_deps, dep_file)
        # update
        del prev_completions
        del prev_tests
        del prev_deps
        prev_completions = cur_completions
        prev_tests = cur_tests
        prev_deps = cur_deps
    
    return max_round





def process_dialogue_for_namespace(
    dialogue, 
    namespace, 
    model,
    tokenizer,
    elements,
    template
):
    """
    å¤„ç†å•ä¸ªå¯¹è¯ï¼Œè¿”å›å¸¦åˆ†æ•°çš„å¯¹è¯æ•°æ®
    
    Args:
        dialogue: å•ä¸ªå¯¹è¯æ•°æ®ï¼ŒåŒ…å«conversationå­—æ®µ
        namespace: å½“å‰å¯¹è¯çš„namespace
        model: å·²åŠ è½½çš„verifieræ¨¡å‹
        tokenizer: å·²åŠ è½½çš„tokenizer
        elements: prompt elements
        template: verifieræ¨¡æ¿
    
    Returns:
        dict: {
            "namespace": "xxx",
            "conversation": [
                {"tutor": "text", "tutor_score": 0.85},
                {"student": "text"},
                {"tutor": "text", "tutor_score": 0.92}
            ]
        }
    """
    print(f"ğŸ” å¼€å§‹å¤„ç†namespace: {namespace}")
    
    # 1. æå–tutor utteranceå¹¶æ„å»ºdataloader
    print("ğŸ”§ æå–tutor utteranceå¹¶æ„å»ºdataloader...")
    tutor_utterances = []
    tutor_indices = []  # è®°å½•tutor utteranceåœ¨å¯¹è¯ä¸­çš„ä½ç½®
    
    for i, turn in enumerate(dialogue["conversation"]):
        if "tutor" in turn:
            tutor_utterances.append(turn["tutor"])
            tutor_indices.append(i)
    
    print(f"ğŸ“ æ‰¾åˆ° {len(tutor_utterances)} ä¸ªtutor utterance")
    
    if len(tutor_utterances) == 0:
        print("âš ï¸ è¯¥å¯¹è¯ä¸­æ²¡æœ‰tutor utterance")
        return {
            "namespace": namespace,
            "conversation": dialogue["conversation"]
        }
    
    # 2. æ„å»ºdataloader
    builder = OfflineDataBuilder(elements, template, tokenizer=tokenizer, max_length=2048)
    builder.set_namespace(namespace)
    
    conversation_list = dialogue["conversation"]
    response_list = tutor_utterances
    
    dataloader = builder.build_data(conversation_list, response_list)
    print(f"âœ… æˆåŠŸæ„å»ºDataLoaderï¼ŒåŒ…å« {len(dataloader)} ä¸ªæ‰¹æ¬¡")
    
    # 3. ä½¿ç”¨æ¨¡å‹æ‰“åˆ†
    print("ğŸ”„ å¼€å§‹æ‰“åˆ†...")
    model.eval()
    scores = []
    
    with torch.no_grad():
        for i, batch in enumerate(dataloader):
            print(f"  å¤„ç†ç¬¬ {i+1}/{len(dataloader)} ä¸ªæ ·æœ¬...")
            
            # å°†æ•°æ®ç§»åˆ°GPU
            device = next(model.parameters()).device
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            # è¿›è¡Œæ¨ç†
            try:
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                
                # æå–åˆ†æ•°
                score_value = outputs['score'].item()  # ä»tensorè½¬æ¢ä¸ºPythonæ•°å€¼
                scores.append(score_value)
                
                print(f"    æ ·æœ¬ {i+1} çš„åˆ†æ•°: {score_value:.4f}")
                
            except Exception as e:
                print(f"    âŒ æ¨ç†ç¬¬ {i+1} ä¸ªæ ·æœ¬æ—¶å‡ºé”™: {e}")
                print("ğŸš« ç»ˆæ­¢è¿›ç¨‹")
                raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œç»ˆæ­¢è¿›ç¨‹
    
    # 4. æ„å»ºè¿”å›ç»“æœ
    print("ğŸ“‹ æ„å»ºè¿”å›ç»“æœ...")
    result_conversation = []
    
    for i, turn in enumerate(dialogue["conversation"]):
        if "tutor" in turn:
            # æ‰¾åˆ°å¯¹åº”çš„åˆ†æ•°
            tutor_idx = tutor_indices.index(i)
            score = scores[tutor_idx]
            
            # æ·»åŠ tutor utteranceå’Œåˆ†æ•°
            result_conversation.append({
                "tutor": turn["tutor"],
                "tutor_score": score
            })
        else:
            # ä¿æŒstudent utteranceä¸å˜
            result_conversation.append(turn)
    
    result = {
        "namespace": namespace,
        "conversation": result_conversation
    }
    
    print(f"âœ… å¯¹è¯å¤„ç†å®Œæˆï¼Œå…±å¤„ç†äº† {len(scores)} ä¸ªtutor utterance")
    return result